{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        index                   field  \\\n",
      "0     1.1.1.1          category1_name   \n",
      "3     1.1.1.4         category1_price   \n",
      "1     1.1.1.2        category1_rating   \n",
      "2     1.1.1.3        category1_review   \n",
      "4     1.2.1.5   category2_description   \n",
      "..        ...                     ...   \n",
      "18   59.2.4.4  category2_rating_count   \n",
      "2    59.2.1.3        category2_review   \n",
      "7    59.2.2.3        category2_review   \n",
      "12   59.2.3.3        category2_review   \n",
      "17   59.2.4.3        category2_review   \n",
      "\n",
      "                                                value  \n",
      "0   CAD Audio U49 USB Large Format Side Address St...  \n",
      "3                                                 Nan  \n",
      "1                                          32 ratings  \n",
      "2                       a-icon a-icon-star a-star-4-5  \n",
      "4                    98% positive over last 12 months  \n",
      "..                                                ...  \n",
      "18                                               4281  \n",
      "2   a-icon a-icon-star-mini a-star-mini-4-5 aod-se...  \n",
      "7   a-icon a-icon-star-mini a-star-mini-4-5 aod-se...  \n",
      "12  a-icon a-icon-star-mini a-star-mini-4-5 aod-se...  \n",
      "17  a-icon a-icon-star-mini a-star-mini-4-5 aod-se...  \n",
      "\n",
      "[2631 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "path_to_json = 'E:/growbydata/Growbydata/task_4/amazoncpi/json/'\n",
    "json_files = [pos_json for pos_json in os.listdir(path_to_json) if pos_json.endswith('.json')]\n",
    "final_json_to_csv_df = pd.DataFrame()\n",
    "from_file = 0\n",
    "index_file_mapping={}\n",
    "\n",
    "def for_category1(df):\n",
    "    # for header\n",
    "    name = df[(df['depth']==16) & (df['element']=='H5')]['text'].reset_index(drop=True)\n",
    "    #print(name)\n",
    "    rating = df[(df['depth']==16)& (df['element']=='SPAN') & (df['height']==16) & (df['x']==716.40625)]['text'].reset_index(drop=True)\n",
    "    #print(rating)\n",
    "    review = df[(df['depth']==17) & (df['element']=='I') & (df['height']==18)]['attributes.class'].reset_index(drop=True)\n",
    "    #print(review)\n",
    "    price = df[(df['depth']==21) & (df['element']=='SPAN') & (df['height']==25) & (df['x']==633)]['text'].unique()\n",
    "    price = pd.Series(price)\n",
    "    #print(price)\n",
    "    #sold_by = df[(df['depth']==17) & (df['element']=='DIV') & (df['height']==20) & (df['width']==397) | (df['width']==382)]['text'].reset_index(drop=True)\n",
    "    #print(sold_by)\n",
    "    #final_dfs = pd.concat([name, rating, review, price, sold_by],  axis=1)\n",
    "    #final_dfs.columns = ['category1_name','category1_rating','category1_review','category1_price','category1_sold_by']\n",
    "    #print(final_dfs['category1_sold_by'])## error\n",
    "    final_dfs = pd.concat([name, rating, review, price],  axis=1)\n",
    "    final_dfs.columns = ['category1_name','category1_rating','category1_review','category1_price']\n",
    "    return(final_dfs)\n",
    "\n",
    "def for_category2(df):\n",
    "    sold_by = df[(df['depth']==14) & (df['element']=='DIV') & (df['height']==20) & (df['x']==633)]['text'].reset_index(drop=True)\n",
    "    #print(sold_by)\n",
    "    if sold_by.empty:\n",
    "        sold_by = price = review = rating_count =description = ['N/A']\n",
    "    else:\n",
    "        price = df[(df['depth']==17) & (df['element']=='SPAN') & (df['height']==25) & (df['width']==79.046875)]['text'].reset_index(drop=True)\n",
    "        #print(price)\n",
    "        review = df[(df['depth']==16) & (df['element']=='I') & (df['height']==12)]['attributes.class'].reset_index(drop=True)\n",
    "        #print(review)\n",
    "        rcount = df[(df['depth']==15) & (df['element']=='DIV') & (df['height']==40) & (df['x']==633)]['text'].reset_index(drop=True)\n",
    "        rcount = rcount[~rcount.str.contains(\"FREE\")] # drop row which conain free text\n",
    "        rcount = rcount[~rcount.str.contains(\"19.95\")]# drop row which conain free 19.95\n",
    "        #print(rcount)\n",
    "        rating_count = rcount.astype(str).str.split(' | ratings',expand=True)[0].str.strip(\"()\").reset_index(drop=True)\n",
    "        #print(rating_count)\n",
    "        description = rcount.astype(str).str.split(')',expand=True)[1].reset_index(drop=True)\n",
    "       # print(description)\n",
    "    final_dfs = pd.concat([sold_by, price, review, rating_count, description],  axis=1)\n",
    "    final_dfs.columns = ['category2_name','category2_price','category2_review','category2_rating_count','category2_description']\n",
    "    #print(final_dfs)\n",
    "    return(final_dfs)\n",
    "\n",
    "\n",
    "for file_name in (json_files):\n",
    "    #print(file_name)\n",
    "    data = json.load(open(f\"./amazoncpi/json/{file_name}\"))\n",
    "    df = pd.json_normalize(data[\"data\"])\n",
    "    df['file_from'] = file_name\n",
    "    #print(df)\n",
    "    # for body data\n",
    "    category = ['category1', 'category2']\n",
    "    from_file = from_file + 1\n",
    "    for l in range(len(category)):\n",
    "        if (l == 0):\n",
    "            final_dfs = for_category1(df)\n",
    "            \n",
    "            indexx = []\n",
    "            field = []\n",
    "            value = []\n",
    "            j=1\n",
    "            for index,content in final_dfs.iterrows():\n",
    "                for i in range(len(content)):\n",
    "                    indexx.append(f\" {from_file}.{l+1}.{j}.{i+1}\")\n",
    "                j=j+1\n",
    "            #print(index)\n",
    "            file_name = file_name.split('.') # for file number\n",
    "            file_name=file_name[0]\n",
    "            index_file_mapping[file_name] = from_file   # for mapping \n",
    "\n",
    "\n",
    "            j=0        \n",
    "            for index,content in final_dfs.iterrows():\n",
    "                for i in range(len(content)):\n",
    "                    field.append(content.index[i])\n",
    "                    value.append(content[i])\n",
    "                    j = j+1\n",
    "\n",
    "            #from_file = from_file + 1\n",
    "            # series\n",
    "            s1 = pd.Series(indexx) \n",
    "            s2 = pd.Series(field)\n",
    "            s3 = pd.Series(value)\n",
    "            final_df =pd.concat([s1, s2, s3], axis=1)\n",
    "            final_df.columns = ['index','field','value']\n",
    "            final_df = final_df.sort_values(by=['field','index'])\n",
    "            #print(final_df)\n",
    "            final_json_to_csv_df = pd.concat([final_json_to_csv_df, final_df])\n",
    "            #print(final_json_to_csv_df)\n",
    "\n",
    "        # for body\n",
    "        else: \n",
    "            final_dfs = for_category2(df)\n",
    "\n",
    "            indexx = []\n",
    "            field = []\n",
    "            value = []\n",
    "            j=1\n",
    "            for index,content in final_dfs.iterrows():\n",
    "                for i in range(len(content)):\n",
    "                    indexx.append(f\" {from_file}.{l+1}.{j}.{i+1}\")\n",
    "                j=j+1\n",
    "            #print(index)\n",
    "            file_name = file_name.split('.') # for file number\n",
    "            file_name=file_name[0]\n",
    "            index_file_mapping[file_name] = from_file   # for mapping \n",
    "\n",
    "\n",
    "            j=0        \n",
    "            for index,content in final_dfs.iterrows():\n",
    "                for i in range(len(content)):\n",
    "                    field.append(content.index[i])\n",
    "                    value.append(content[i])\n",
    "                    j = j+1\n",
    "\n",
    "            #from_file = from_file + 1\n",
    "            # series\n",
    "            s1 = pd.Series(indexx) \n",
    "            s2 = pd.Series(field)\n",
    "            s3 = pd.Series(value)\n",
    "            final_df =pd.concat([s1, s2, s3], axis=1)\n",
    "            final_df.columns = ['index','field','value']\n",
    "            final_df = final_df.sort_values(by=['field','index'])\n",
    "            #print(final_df)\n",
    "            final_json_to_csv_df = pd.concat([final_json_to_csv_df, final_df])\n",
    "final_json_to_csv_df = final_json_to_csv_df.fillna('Nan')\n",
    "print(final_json_to_csv_df)\n",
    "#final_json_to_csv_df.to_csv(\"final_task14.csv\",index=False)\n",
    "index_file_mapping_df = pd.DataFrame(list(index_file_mapping.items()), columns = ['file_name','Indexing'])\n",
    "#print(index_file_mapping_df)\n",
    "index_file_mapping_df.to_csv('map_index_t4.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       index                  field  \\\n",
      "0    1.1.1.1         category1_name   \n",
      "3    1.1.1.4        category1_price   \n",
      "1    1.1.1.2       category1_rating   \n",
      "2    1.1.1.3       category1_review   \n",
      "4    1.2.1.5  category2_description   \n",
      "..       ...                    ...   \n",
      "7    3.2.2.3       category2_review   \n",
      "12   3.2.3.3       category2_review   \n",
      "17   3.2.4.3       category2_review   \n",
      "22   3.2.5.3       category2_review   \n",
      "27   3.2.6.3       category2_review   \n",
      "\n",
      "                                                value  \n",
      "0   CAD Audio, 2 GXLD2HBAH Digital Wireless Combo ...  \n",
      "3                                             $202.24  \n",
      "1                                           2 ratings  \n",
      "2                         a-icon a-icon-star a-star-4  \n",
      "4                    91% positive over last 12 months  \n",
      "..                                                ...  \n",
      "7   a-icon a-icon-star-mini a-star-mini-4-5 aod-se...  \n",
      "12  a-icon a-icon-star-mini a-star-mini-4-5 aod-se...  \n",
      "17  a-icon a-icon-star-mini a-star-mini-4-5 aod-se...  \n",
      "22  a-icon a-icon-star-mini a-star-mini-4-5 aod-se...  \n",
      "27  a-icon a-icon-star-mini a-star-mini-4-5 aod-se...  \n",
      "\n",
      "[147 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "path_to_json = 'E:/growbydata/Growbydata/task_4/amazoncpi/json/'\n",
    "json_files = [pos_json for pos_json in os.listdir(path_to_json) if pos_json.endswith('.json')]\n",
    "final_json_to_csv_df = pd.DataFrame()\n",
    "from_file = 0\n",
    "index_file_mapping={}\n",
    "\n",
    "def for_category1(df):\n",
    "    # for header\n",
    "    name = df[(df['depth']==16) & (df['element']=='H5')]['text'].reset_index(drop=True)\n",
    "    #print(name)\n",
    "    rating = df[(df['depth']==16)& (df['element']=='SPAN') & (df['height']==16) & (df['x']==716.40625)]['text'].reset_index(drop=True)\n",
    "    #print(rating)\n",
    "    review = df[(df['depth']==17) & (df['element']=='I') & (df['height']==18)]['attributes.class'].reset_index(drop=True)\n",
    "    #print(review)\n",
    "    price = df[(df['depth']==21) & (df['element']=='SPAN') & (df['height']==25) & (df['x']==633)]['text'].unique()\n",
    "    price = pd.Series(price)\n",
    "    #print(price)\n",
    "    #sold_by = df[(df['depth']==17) & (df['element']=='DIV') & (df['height']==20) & (df['width']==397) | (df['width']==382)]['text'].reset_index(drop=True)\n",
    "    #print(sold_by)\n",
    "    #final_dfs = pd.concat([name, rating, review, price, sold_by],  axis=1)\n",
    "    #final_dfs.columns = ['category1_name','category1_rating','category1_review','category1_price','category1_sold_by']\n",
    "    #print(final_dfs['category1_sold_by'])## error\n",
    "    final_dfs = pd.concat([name, rating, review, price],  axis=1)\n",
    "    final_dfs.columns = ['category1_name','category1_rating','category1_review','category1_price']\n",
    "    return(final_dfs)\n",
    "\n",
    "def for_category2(df):\n",
    "    sold_by = df[(df['depth']==14) & (df['element']=='DIV') & (df['height']==20) & (df['x']==633)]['text'].reset_index(drop=True)\n",
    "    #print(sold_by)\n",
    "    price = df[(df['depth']==17) & (df['element']=='SPAN') & (df['height']==25) & (df['width']==79.046875)]['text'].reset_index(drop=True)\n",
    "    #print(price)\n",
    "    review = df[(df['depth']==16) & (df['element']=='I') & (df['height']==12)]['attributes.class'].reset_index(drop=True)\n",
    "    #print(review)\n",
    "    rcount = df[(df['depth']==15) & (df['element']=='DIV') & (df['height']==40) & (df['x']==633)]['text'].reset_index(drop=True)\n",
    "    rcount = rcount[~rcount.str.contains(\"FREE\")] # drop row which conain free text\n",
    "    rcount = rcount[~rcount.str.contains(\"19.95\")]# drop row which conain free 19.95\n",
    "    #print(rcount)\n",
    "    rating_count = rcount.astype(str).str.split(' | ratings',expand=True)[0].str.strip(\"()\").reset_index(drop=True)\n",
    "    #print(rating_count)\n",
    "    description = rcount.astype(str).str.split(')',expand=True)[1].reset_index(drop=True)\n",
    "   # print(description)\n",
    "    final_dfs = pd.concat([sold_by, price, review, rating_count, description],  axis=1)\n",
    "    final_dfs.columns = ['category2_name','category2_price','category2_review','category2_rating_count','category2_description']\n",
    "    #print(final_dfs)\n",
    "    return(final_dfs)\n",
    "\n",
    "\n",
    "for file_name in (json_files):\n",
    "    #print(file_name)\n",
    "    data = json.load(open(f\"./amazoncpi/json/{file_name}\"))\n",
    "    df = pd.json_normalize(data[\"data\"])\n",
    "    df['file_from'] = file_name\n",
    "    #print(df)\n",
    "    # for body data\n",
    "    category = ['category1', 'category2']\n",
    "    from_file = from_file + 1\n",
    "    for l in range(len(category)):\n",
    "        if (l == 0):\n",
    "            final_dfs = for_category1(df)\n",
    "            \n",
    "            indexx = []\n",
    "            field = []\n",
    "            value = []\n",
    "            j=1\n",
    "            for index,content in final_dfs.iterrows():\n",
    "                for i in range(len(content)):\n",
    "                    indexx.append(f\" {from_file}.{l+1}.{j}.{i+1}\")\n",
    "                j=j+1\n",
    "            #print(index)\n",
    "            file_name = file_name.split('.') # for file number\n",
    "            file_name=file_name[0]\n",
    "            index_file_mapping[file_name] = from_file   # for mapping \n",
    "\n",
    "\n",
    "            j=0        \n",
    "            for index,content in final_dfs.iterrows():\n",
    "                for i in range(len(content)):\n",
    "                    field.append(content.index[i])\n",
    "                    value.append(content[i])\n",
    "                    j = j+1\n",
    "\n",
    "            #from_file = from_file + 1\n",
    "            # series\n",
    "            s1 = pd.Series(indexx) \n",
    "            s2 = pd.Series(field)\n",
    "            s3 = pd.Series(value)\n",
    "            final_df =pd.concat([s1, s2, s3], axis=1)\n",
    "            final_df.columns = ['index','field','value']\n",
    "            final_df = final_df.sort_values(by=['field','index'])\n",
    "            #print(final_df)\n",
    "            final_json_to_csv_df = pd.concat([final_json_to_csv_df, final_df])\n",
    "            #print(final_json_to_csv_df)\n",
    "\n",
    "        # for body\n",
    "        else: \n",
    "            \n",
    "            final_dfs = for_category2(df)\n",
    "\n",
    "            indexx = []\n",
    "            field = []\n",
    "            value = []\n",
    "            j=1\n",
    "            for index,content in final_dfs.iterrows():\n",
    "                for i in range(len(content)):\n",
    "                    indexx.append(f\" {from_file}.{l+1}.{j}.{i+1}\")\n",
    "                j=j+1\n",
    "            #print(index)\n",
    "            file_name = file_name.split('.') # for file number\n",
    "            file_name=file_name[0]\n",
    "            index_file_mapping[file_name] = from_file   # for mapping \n",
    "\n",
    "\n",
    "            j=0        \n",
    "            for index,content in final_dfs.iterrows():\n",
    "                for i in range(len(content)):\n",
    "                    field.append(content.index[i])\n",
    "                    value.append(content[i])\n",
    "                    j = j+1\n",
    "\n",
    "            #from_file = from_file + 1\n",
    "            # series\n",
    "            s1 = pd.Series(indexx) \n",
    "            s2 = pd.Series(field)\n",
    "            s3 = pd.Series(value)\n",
    "            final_df =pd.concat([s1, s2, s3], axis=1)\n",
    "            final_df.columns = ['index','field','value']\n",
    "            final_df = final_df.sort_values(by=['field','index'])\n",
    "            #print(final_df)\n",
    "            final_json_to_csv_df = pd.concat([final_json_to_csv_df, final_df])\n",
    "final_json_to_csv_df = final_json_to_csv_df.fillna('Nan')\n",
    "print(final_json_to_csv_df)\n",
    "#final_json_to_csv_df.to_csv(\"final_task14.csv\",index=False)\n",
    "#index_file_mapping_df = pd.DataFrame(list(index_file_mapping.items()), columns = ['file_name','Indexing'])\n",
    "#print(index_file_mapping_df)\n",
    "#index_file_mapping_df.to_csv('map_index_t4.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        index                   field  \\\n",
      "0     1.1.1.1          category1_name   \n",
      "3     1.1.1.4         category1_price   \n",
      "1     1.1.1.2        category1_rating   \n",
      "2     1.1.1.3        category1_review   \n",
      "4     1.2.1.5   category2_description   \n",
      "..        ...                     ...   \n",
      "18   59.2.4.4  category2_rating_count   \n",
      "2    59.2.1.3        category2_review   \n",
      "7    59.2.2.3        category2_review   \n",
      "12   59.2.3.3        category2_review   \n",
      "17   59.2.4.3        category2_review   \n",
      "\n",
      "                                                value  \n",
      "0   CAD Audio U49 USB Large Format Side Address St...  \n",
      "3                                                 Nan  \n",
      "1                                          32 ratings  \n",
      "2                       a-icon a-icon-star a-star-4-5  \n",
      "4                    98% positive over last 12 months  \n",
      "..                                                ...  \n",
      "18                                               4281  \n",
      "2   a-icon a-icon-star-mini a-star-mini-4-5 aod-se...  \n",
      "7   a-icon a-icon-star-mini a-star-mini-4-5 aod-se...  \n",
      "12  a-icon a-icon-star-mini a-star-mini-4-5 aod-se...  \n",
      "17  a-icon a-icon-star-mini a-star-mini-4-5 aod-se...  \n",
      "\n",
      "[2631 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "path_to_json = 'E:/growbydata/Growbydata/task_4/amazoncpi/json/'\n",
    "json_files = [pos_json for pos_json in os.listdir(path_to_json) if pos_json.endswith('.json')]\n",
    "final_json_to_csv_df = pd.DataFrame()\n",
    "from_file = 0\n",
    "index_file_mapping={}\n",
    "\n",
    "def for_category1(df):\n",
    "    # for header\n",
    "    name = df[(df['depth']==16) & (df['element']=='H5')]['text'].reset_index(drop=True)\n",
    "    #print(name)\n",
    "    rating = df[(df['depth']==16)& (df['element']=='SPAN') & (df['height']==16) & (df['x']==716.40625)]['text'].reset_index(drop=True)\n",
    "    #print(rating)\n",
    "    review = df[(df['depth']==17) & (df['element']=='I') & (df['height']==18)]['attributes.class'].reset_index(drop=True)\n",
    "    #print(review)\n",
    "    price = df[(df['depth']==21) & (df['element']=='SPAN') & (df['height']==25) & (df['x']==633)]['text'].unique()\n",
    "    price = pd.Series(price)\n",
    "    #print(price)\n",
    "    #sold_by = df[(df['depth']==17) & (df['element']=='DIV') & (df['height']==20) & (df['width']==397) | (df['width']==382)]['text'].reset_index(drop=True)\n",
    "    #print(sold_by)\n",
    "    #final_dfs = pd.concat([name, rating, review, price, sold_by],  axis=1)\n",
    "    #final_dfs.columns = ['category1_name','category1_rating','category1_review','category1_price','category1_sold_by']\n",
    "    #print(final_dfs['category1_sold_by'])## error\n",
    "    final_dfs = pd.concat([name, rating, review, price],  axis=1)\n",
    "    final_dfs.columns = ['category1_name','category1_rating','category1_review','category1_price']\n",
    "    return(final_dfs)\n",
    "\n",
    "def for_category2(df):\n",
    "    sold_by = df[(df['depth']==14) & (df['element']=='DIV') & (df['height']==20) & (df['x']==633)]['text'].reset_index(drop=True)\n",
    "    #print(sold_by)\n",
    "    if sold_by.empty:\n",
    "        sold_by = price = review = rating_count =description = ['N/A']\n",
    "    else:\n",
    "        price = df[(df['depth']==17) & (df['element']=='SPAN') & (df['height']==25) & (df['width']==79.046875)]['text'].reset_index(drop=True)\n",
    "        #print(price)\n",
    "        review = df[(df['depth']==16) & (df['element']=='I') & (df['height']==12)]['attributes.class'].reset_index(drop=True)\n",
    "        #print(review)\n",
    "        rcount = df[(df['depth']==15) & (df['element']=='DIV') & (df['height']==40) & (df['x']==633)]['text'].reset_index(drop=True)\n",
    "        rcount = rcount[~rcount.str.contains(\"FREE\")] # drop row which conain free text\n",
    "        rcount = rcount[~rcount.str.contains(\"19.95\")]# drop row which conain free 19.95\n",
    "        #print(rcount)\n",
    "        rating_count = rcount.astype(str).str.split(' | ratings',expand=True)[0].str.strip(\"()\").reset_index(drop=True)\n",
    "        #print(rating_count)\n",
    "        description = rcount.astype(str).str.split(')',expand=True)[1].reset_index(drop=True)\n",
    "       # print(description)\n",
    "    final_dfs = pd.concat([sold_by, price, review, rating_count, description],  axis=1)\n",
    "    final_dfs.columns = ['category2_name','category2_price','category2_review','category2_rating_count','category2_description']\n",
    "    #print(final_dfs)\n",
    "    return(final_dfs)\n",
    "\n",
    "\n",
    "for file_name in (json_files):\n",
    "    #print(file_name)\n",
    "    data = json.load(open(f\"./amazoncpi/json/{file_name}\"))\n",
    "    df = pd.json_normalize(data[\"data\"])\n",
    "    df['file_from'] = file_name\n",
    "    #print(df)\n",
    "    # for body data\n",
    "    category = ['category1', 'category2']\n",
    "    from_file = from_file + 1\n",
    "    for l in range(len(category)):\n",
    "        if (l == 0):\n",
    "            final_dfs = for_category1(df)\n",
    "            #print(final_dfs)\n",
    "            \n",
    "            indexx = []\n",
    "            field = []\n",
    "            value = []\n",
    "            j=1\n",
    "            for index,content in final_dfs.iterrows():\n",
    "                for i in range(len(content)):\n",
    "                    indexx.append(f\" {from_file}.{l+1}.{j}.{i+1}\")\n",
    "                j=j+1\n",
    "            #print(index)\n",
    "            file_name = file_name.split('.') # for file number\n",
    "            file_name=file_name[0]\n",
    "            index_file_mapping[file_name] = from_file   # for mapping \n",
    "\n",
    "\n",
    "            j=0        \n",
    "            for index,content in final_dfs.iterrows():\n",
    "                for i in range(len(content)):\n",
    "                    field.append(content.index[i])\n",
    "                    value.append(content[i])\n",
    "                    j = j+1\n",
    "\n",
    "            #from_file = from_file + 1\n",
    "            # series\n",
    "            s1 = pd.Series(indexx) \n",
    "            s2 = pd.Series(field)\n",
    "            s3 = pd.Series(value)\n",
    "            final_df =pd.concat([s1, s2, s3], axis=1)\n",
    "            final_df.columns = ['index','field','value']\n",
    "            final_df = final_df.sort_values(by=['field','index'])\n",
    "            #print(final_df)\n",
    "            final_json_to_csv_df = pd.concat([final_json_to_csv_df, final_df])\n",
    "            #print(final_json_to_csv_df)\n",
    "\n",
    "        # for body\n",
    "        else: \n",
    "            pass\n",
    "            final_dfs = for_category2(df)\n",
    "\n",
    "            indexx = []\n",
    "            field = []\n",
    "            value = []\n",
    "            j=1\n",
    "            for index,content in final_dfs.iterrows():\n",
    "                for i in range(len(content)):\n",
    "                    indexx.append(f\" {from_file}.{l+1}.{j}.{i+1}\")\n",
    "                j=j+1\n",
    "            #print(index)\n",
    "            file_name = file_name.split('.') # for file number\n",
    "            file_name=file_name[0]\n",
    "            index_file_mapping[file_name] = from_file   # for mapping \n",
    "\n",
    "\n",
    "            j=0        \n",
    "            for index,content in final_dfs.iterrows():\n",
    "                for i in range(len(content)):\n",
    "                    field.append(content.index[i])\n",
    "                    value.append(content[i])\n",
    "                    j = j+1\n",
    "\n",
    "            #from_file = from_file + 1\n",
    "            # series\n",
    "            s1 = pd.Series(indexx) \n",
    "            s2 = pd.Series(field)\n",
    "            s3 = pd.Series(value)\n",
    "            final_df =pd.concat([s1, s2, s3], axis=1)\n",
    "            final_df.columns = ['index','field','value']\n",
    "            final_df = final_df.sort_values(by=['field','index'])\n",
    "            #print(final_df)\n",
    "            final_json_to_csv_df = pd.concat([final_json_to_csv_df, final_df])\n",
    "final_json_to_csv_df = final_json_to_csv_df.fillna('Nan')\n",
    "print(final_json_to_csv_df)\n",
    "#final_json_to_csv_df.to_csv(\"final_task444.csv\",index=False)\n",
    "#index_file_mapping_df = pd.DataFrame(list(index_file_mapping.items()), columns = ['file_name','Indexing'])\n",
    "#print(index_file_mapping_df)\n",
    "#index_file_mapping_df.to_csv('map_index_t4.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        index                   field  \\\n",
      "0     1.1.1.1          category1_name   \n",
      "3     1.1.1.4         category1_price   \n",
      "1     1.1.1.2        category1_rating   \n",
      "2     1.1.1.3        category1_review   \n",
      "4     1.2.1.5   category2_description   \n",
      "..        ...                     ...   \n",
      "18   59.2.4.4  category2_rating_count   \n",
      "2    59.2.1.3        category2_review   \n",
      "7    59.2.2.3        category2_review   \n",
      "12   59.2.3.3        category2_review   \n",
      "17   59.2.4.3        category2_review   \n",
      "\n",
      "                                                value  \n",
      "0   CAD Audio U49 USB Large Format Side Address St...  \n",
      "3                                                 Nan  \n",
      "1                                          32 ratings  \n",
      "2                       a-icon a-icon-star a-star-4-5  \n",
      "4                    98% positive over last 12 months  \n",
      "..                                                ...  \n",
      "18                                               4281  \n",
      "2   a-icon a-icon-star-mini a-star-mini-4-5 aod-se...  \n",
      "7   a-icon a-icon-star-mini a-star-mini-4-5 aod-se...  \n",
      "12  a-icon a-icon-star-mini a-star-mini-4-5 aod-se...  \n",
      "17  a-icon a-icon-star-mini a-star-mini-4-5 aod-se...  \n",
      "\n",
      "[2631 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "path_to_json = 'E:/growbydata/Growbydata/task_4/amazoncpi/json/'\n",
    "json_files = [pos_json for pos_json in os.listdir(path_to_json) if pos_json.endswith('.json')]\n",
    "final_json_to_csv_df = pd.DataFrame()\n",
    "from_file = 0\n",
    "index_file_mapping={}\n",
    "\n",
    "def for_category1(df):\n",
    "    name = df[(df['depth']==16) & (df['element']=='H5')]['text'].reset_index(drop=True)\n",
    "    rating = df[(df['depth']==16)& (df['element']=='SPAN') & (df['height']==16) & (df['x']==716.40625)]['text'].reset_index(drop=True)\n",
    "    review = df[(df['depth']==17) & (df['element']=='I') & (df['height']==18)]['attributes.class'].reset_index(drop=True)\n",
    "    price = df[(df['depth']==21) & (df['element']=='SPAN') & (df['height']==25) & (df['x']==633)]['text'].unique()\n",
    "    price = pd.Series(price)\n",
    "    final_dfs = pd.concat([name, rating, review, price],  axis=1)\n",
    "    final_dfs.columns = ['category1_name','category1_rating','category1_review','category1_price']\n",
    "    return(final_dfs)\n",
    "\n",
    "def for_category2(df):\n",
    "    sold_by = df[(df['depth']==14) & (df['element']=='DIV') & (df['height']==20) & (df['x']==633)]['text'].reset_index(drop=True)\n",
    "    if sold_by.empty:\n",
    "        sold_by = price = review = rating_count =description = ['N/A']\n",
    "    else:\n",
    "        price = df[(df['depth']==17) & (df['element']=='SPAN') & (df['height']==25) & (df['width']==79.046875)]['text'].reset_index(drop=True)\n",
    "        review = df[(df['depth']==16) & (df['element']=='I') & (df['height']==12)]['attributes.class'].reset_index(drop=True)\n",
    "        rcount = df[(df['depth']==15) & (df['element']=='DIV') & (df['height']==40) & (df['x']==633)]['text'].reset_index(drop=True)\n",
    "        rcount = rcount[~rcount.str.contains(\"FREE\")] # drop row which conain free text\n",
    "        rcount = rcount[~rcount.str.contains(\"19.95\")]# drop row which conain free 19.95\n",
    "        rating_count = rcount.astype(str).str.split(' | ratings',expand=True)[0].str.strip(\"()\").reset_index(drop=True)\n",
    "        description = rcount.astype(str).str.split(')',expand=True)[1].reset_index(drop=True)\n",
    "    final_dfs = pd.concat([sold_by, price, review, rating_count, description],  axis=1)\n",
    "    final_dfs.columns = ['category2_name','category2_price','category2_review','category2_rating_count','category2_description']\n",
    "    #print(final_dfs)\n",
    "    return(final_dfs)\n",
    "\n",
    "def for_indexing(final_dfs, l, file_name):\n",
    "    indexx = []\n",
    "    field = []\n",
    "    value = []\n",
    "    j=1\n",
    "    for index,content in final_dfs.iterrows():\n",
    "        for i in range(len(content)):\n",
    "            indexx.append(f\" {from_file}.{l+1}.{j}.{i+1}\")\n",
    "        j=j+1\n",
    "    #print(index)\n",
    "    file_name = file_name.split('.') # for file number\n",
    "    file_name=file_name[0]\n",
    "    index_file_mapping[file_name] = from_file   # for mapping \n",
    "\n",
    "    j=0        \n",
    "    for index,content in final_dfs.iterrows():\n",
    "        for i in range(len(content)):\n",
    "            field.append(content.index[i])\n",
    "            value.append(content[i])\n",
    "            j = j+1\n",
    "\n",
    "    # series\n",
    "    s1 = pd.Series(indexx) \n",
    "    s2 = pd.Series(field)\n",
    "    s3 = pd.Series(value)\n",
    "    final_df =pd.concat([s1, s2, s3], axis=1)\n",
    "    final_df.columns = ['index','field','value']\n",
    "    final_df = final_df.sort_values(by=['field','index'])\n",
    "    return(final_df)\n",
    "\n",
    "\n",
    "for file_name in (json_files):\n",
    "    #print(file_name)\n",
    "    data = json.load(open(f\"./amazoncpi/json/{file_name}\"))\n",
    "    df = pd.json_normalize(data[\"data\"])\n",
    "    df['file_from'] = file_name\n",
    "    #print(df)\n",
    "    category = ['category1', 'category2']\n",
    "    from_file = from_file + 1\n",
    "    for l in range(len(category)):\n",
    "        if (l == 0):\n",
    "            final_dfs = for_category1(df)            \n",
    "            final_df = for_indexing(final_dfs, l, file_name)\n",
    "            final_json_to_csv_df = pd.concat([final_json_to_csv_df, final_df])\n",
    "            #print(final_json_to_csv_df)\n",
    "        else: \n",
    "            final_dfs = for_category2(df)\n",
    "            final_df = for_indexing(final_dfs, l, file_name)\n",
    "            final_json_to_csv_df = pd.concat([final_json_to_csv_df, final_df])\n",
    "final_json_to_csv_df = final_json_to_csv_df.fillna('Nan')\n",
    "print(final_json_to_csv_df)\n",
    "#final_json_to_csv_df.to_csv(\"final_task444.csv\",index=False)\n",
    "index_file_mapping_df = pd.DataFrame(list(index_file_mapping.items()), columns = ['file_name','Indexing'])\n",
    "#print(index_file_mapping_df)\n",
    "#index_file_mapping_df.to_csv('map_index_t4.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "path_to_json = 'E:/growbydata/Growbydata/task_4/amazoncpi/json/'\n",
    "json_files = [pos_json for pos_json in os.listdir(path_to_json) if pos_json.endswith('.json')]\n",
    "final_json_to_csv_df = pd.DataFrame()\n",
    "from_file = 0\n",
    "index_file_mapping={}\n",
    "\n",
    "def category1(df):\n",
    "    name = df[(df['depth']==16) & (df['element']=='H5')]['text'].reset_index(drop=True)\n",
    "    rating = df[(df['depth']==16)& (df['element']=='SPAN') & (df['height']==16) & (df['x']==716.40625)]['text'].reset_index(drop=True)\n",
    "    review = df[(df['depth']==17) & (df['element']=='I') & (df['height']==18)]['attributes.class'].reset_index(drop=True)\n",
    "    price = df[(df['depth']==21) & (df['element']=='SPAN') & (df['height']==25) & (df['x']==633)]['text'].unique()\n",
    "    price = pd.Series(price)\n",
    "    final_dfs = pd.concat([name, rating, review, price],  axis=1)\n",
    "    final_dfs.columns = ['category1_name','category1_rating','category1_review','category1_price']\n",
    "    return(final_dfs)\n",
    "\n",
    "def category2(df):\n",
    "    sold_by = df[(df['depth']==14) & (df['element']=='DIV') & (df['height']==20) & (df['x']==633)]['text'].reset_index(drop=True)\n",
    "    price = df[(df['depth']==17) & (df['element']=='SPAN') & (df['height']==25) & (df['width']==79.046875)]['text'].reset_index(drop=True)\n",
    "    review = df[(df['depth']==16) & (df['element']=='I') & (df['height']==12)]['attributes.class'].reset_index(drop=True)\n",
    "    rcount = df[(df['depth']==15) & (df['element']=='DIV') & (df['height']==40) & (df['x']==633)]['text'].reset_index(drop=True)\n",
    "    rcount = rcount[~rcount.str.contains(\"FREE\")] # drop row which conain free text\n",
    "    rcount = rcount[~rcount.str.contains(\"19.95\")]# drop row which conain free 19.95\n",
    "    rating_count = rcount.astype(str).str.split(' | ratings',expand=True)[0].str.strip(\"()\").reset_index(drop=True)\n",
    "    description = rcount.astype(str).str.split(')',expand=True)[1].reset_index(drop=True)\n",
    "    final_dfs = pd.concat([sold_by, price, review, rating_count, description],  axis=1)\n",
    "    final_dfs.columns = ['category2_name','category2_price','category2_review','category2_rating_count','category2_description']\n",
    "    #print(final_dfs)\n",
    "    return(final_dfs)\n",
    "\n",
    "def indexing(final_dfs, l, file_name):\n",
    "    indexx = []\n",
    "    field = []\n",
    "    value = []\n",
    "    j=1\n",
    "    for index,content in final_dfs.iterrows():\n",
    "        for i in range(len(content)):\n",
    "            indexx.append(f\" {from_file}.{l+1}.{j}.{i+1}\")\n",
    "        j=j+1\n",
    "    #print(index)\n",
    "    file_name = file_name.split('.') # for file number\n",
    "    file_name=file_name[0]\n",
    "    index_file_mapping[file_name] = from_file   # for mapping \n",
    "\n",
    "    j=0        \n",
    "    for index,content in final_dfs.iterrows():\n",
    "        for i in range(len(content)):\n",
    "            field.append(content.index[i])\n",
    "            value.append(content[i])\n",
    "            j = j+1\n",
    "\n",
    "    # series\n",
    "    s1 = pd.Series(indexx) \n",
    "    s2 = pd.Series(field)\n",
    "    s3 = pd.Series(value)\n",
    "    final_df =pd.concat([s1, s2, s3], axis=1)\n",
    "    final_df.columns = ['index','field','value']\n",
    "    final_df = final_df.sort_values(by=['field','index'])\n",
    "    return(final_df)\n",
    "\n",
    "\n",
    "for file_name in (json_files):\n",
    "    #print(file_name)\n",
    "    data = json.load(open(f\"./amazoncpi/json/{file_name}\"))\n",
    "    df = pd.json_normalize(data[\"data\"])\n",
    "    df['file_from'] = file_name\n",
    "    #print(df)\n",
    "    category = ['category1', 'category2']\n",
    "    from_file = from_file + 1\n",
    "    for l in range(len(category)):\n",
    "        if (l == 0):\n",
    "            final_dfs = category1(df)            \n",
    "            final_df = indexing(final_dfs, l, file_name)\n",
    "            final_json_to_csv_df = pd.concat([final_json_to_csv_df, final_df])\n",
    "            #print(final_json_to_csv_df)\n",
    "        else: \n",
    "            final_dfs = category2(df)\n",
    "            final_df = indexing(final_dfs, l, file_name)\n",
    "            final_json_to_csv_df = pd.concat([final_json_to_csv_df, final_df])\n",
    "final_json_to_csv_df = final_json_to_csv_df.fillna('Nan')\n",
    "print(final_json_to_csv_df)\n",
    "final_json_to_csv_df.to_csv(\"final_task4.csv\",index=False)\n",
    "index_file_mapping_df = pd.DataFrame(list(index_file_mapping.items()), columns = ['file_name','Indexing'])\n",
    "#print(index_file_mapping_df)\n",
    "#index_file_mapping_df.to_csv('map_index_t4.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
