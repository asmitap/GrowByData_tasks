{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=Warning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 text     text  \\\n",
      "0  Consumer Supply Co  $195.00   \n",
      "1             AVLGear      NaN   \n",
      "\n",
      "                                    attributes.class     0  \\\n",
      "0  a-icon a-icon-star-mini a-star-mini-4-5 aod-se...   538   \n",
      "1  a-icon a-icon-star-mini a-star-mini-4-5 aod-se...  4281   \n",
      "\n",
      "                                  1  \n",
      "0  87% positive over last 12 months  \n",
      "1  84% positive over last 12 months  \n"
     ]
    }
   ],
   "source": [
    "path_to_json = 'E:/growbydata/Growbydata/task_4/amazoncpi/json/'\n",
    "json_files = [pos_json for pos_json in os.listdir(path_to_json) if pos_json.endswith('.json')]\n",
    "final_json_to_csv_df = pd.DataFrame()\n",
    "for file_name in (json_files):\n",
    "    data = json.load(open(f\"./amazoncpi/json/{file_name}\"))\n",
    "    df = pd.json_normalize(data[\"data\"])\n",
    "    # for header\n",
    "    name = df[(df['depth']==16) & (df['element']=='H5')]['text'].reset_index(drop=True)\n",
    "    #print(name)\n",
    "    rating = df[(df['depth']==16)& (df['element']=='SPAN') & (df['height']==16) & (df['x']==716.40625)]['text'].reset_index(drop=True)\n",
    "    #print(rating)\n",
    "    review = df[(df['depth']==17) & (df['element']=='I') & (df['height']==18)]['attributes.class'].reset_index(drop=True)\n",
    "    #print(review)\n",
    "    price = df[(df['depth']==21) & (df['element']=='SPAN') & (df['height']==25) & (df['x']==633)]['text'].unique()\n",
    "    price = pd.Series(price)\n",
    "    #print(price)\n",
    "    sold_by = df[(df['depth']==17) & (df['element']=='DIV') & (df['height']==20) & (df['width']==397) | (df['width']==382)]['text'].reset_index(drop=True)\n",
    "    #print(sold_by)\n",
    "    header_df = pd.concat([name, rating, review, price, sold_by],  axis=1)\n",
    "    header_df.columns = ['name','raring','review','price','sold_by']\n",
    "    #print(header_df)\n",
    "    #header_df.to_csv('Header.csv')\n",
    "    \n",
    "    \n",
    "    \n",
    "    # for body\n",
    "    sold_by = df[(df['depth']==14) & (df['element']=='DIV') & (df['height']==20) & (df['x']==633)]['text'].reset_index(drop=True)\n",
    "    #print(sold_by)\n",
    "    price = df[(df['depth']==17) & (df['element']=='SPAN') & (df['height']==25) & (df['width']==79.046875)]['text'].reset_index(drop=True)\n",
    "    #print(price)\n",
    "    review = df[(df['depth']==16) & (df['element']=='I') & (df['height']==12)]['attributes.class'].reset_index(drop=True)\n",
    "    #print(review)\n",
    "    rcount = df[(df['depth']==15) & (df['element']=='DIV') & (df['height']==40) & (df['x']==633)]['text'].reset_index(drop=True)\n",
    "    rcount = rcount[~rcount.str.contains(\"FREE\")] # drop row which conain free text\n",
    "    rcount = rcount[~rcount.str.contains(\"19.95\")]# drop row which conain free 19.95\n",
    "    #print(rcount)\n",
    "    rating_count = rcount.astype(str).str.split(' | ratings',expand=True)[0].str.strip(\"()\").reset_index(drop=True)\n",
    "    #print(rating_count)\n",
    "    description = rcount.astype(str).str.split(')',expand=True)[1].reset_index(drop=True)\n",
    "   # print(description)\n",
    "    body_df = pd.concat([sold_by, price, review, rating_count, description],  axis=1)\n",
    "    print(body_df)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        index                   field  \\\n",
      "0     1.1.1.1          category1_name   \n",
      "45   1.1.10.1          category1_name   \n",
      "50   1.1.11.1          category1_name   \n",
      "55   1.1.12.1          category1_name   \n",
      "60   1.1.13.1          category1_name   \n",
      "..        ...                     ...   \n",
      "6     2.2.2.2         category2_price   \n",
      "3     2.2.1.4  category2_rating_count   \n",
      "8     2.2.2.4  category2_rating_count   \n",
      "2     2.2.1.3        category2_review   \n",
      "7     2.2.2.3        category2_review   \n",
      "\n",
      "                                                value  \n",
      "0   CAD Audio, 2 GXLD2HBAH Digital Wireless Combo ...  \n",
      "45                                                NaN  \n",
      "50                                                NaN  \n",
      "55                                                NaN  \n",
      "60                                                NaN  \n",
      "..                                                ...  \n",
      "6                                                 NaN  \n",
      "3                                                 538  \n",
      "8                                                4281  \n",
      "2   a-icon a-icon-star-mini a-star-mini-4-5 aod-se...  \n",
      "7   a-icon a-icon-star-mini a-star-mini-4-5 aod-se...  \n",
      "\n",
      "[280 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "path_to_json = 'E:/growbydata/Growbydata/task_4/amazoncpi/json/'\n",
    "json_files = [pos_json for pos_json in os.listdir(path_to_json) if pos_json.endswith('.json')]\n",
    "final_json_to_csv_df = pd.DataFrame()\n",
    "from_file = 0\n",
    "index_file_mapping={}\n",
    "\n",
    "for file_name in (json_files):\n",
    "    #print(file_name)\n",
    "    data = json.load(open(f\"./amazoncpi/json/{file_name}\"))\n",
    "    df = pd.json_normalize(data[\"data\"])\n",
    "    df['file_from'] = file_name\n",
    "    #print(df)\n",
    "    # for body data\n",
    "    category = ['category1', 'category2']\n",
    "    \n",
    "    from_file = from_file + 1\n",
    "    for l in range(len(category)):\n",
    "        if (l == 0):\n",
    "            df = pd.json_normalize(data[\"data\"])\n",
    "            # for header\n",
    "            name = df[(df['depth']==16) & (df['element']=='H5')]['text'].reset_index(drop=True)\n",
    "            #print(name)\n",
    "            rating = df[(df['depth']==16)& (df['element']=='SPAN') & (df['height']==16) & (df['x']==716.40625)]['text'].reset_index(drop=True)\n",
    "            #print(rating)\n",
    "            review = df[(df['depth']==17) & (df['element']=='I') & (df['height']==18)]['attributes.class'].reset_index(drop=True)\n",
    "            #print(review)\n",
    "            price = df[(df['depth']==21) & (df['element']=='SPAN') & (df['height']==25) & (df['x']==633)]['text'].unique()\n",
    "            price = pd.Series(price)\n",
    "            #print(price)\n",
    "            sold_by = df[(df['depth']==17) & (df['element']=='DIV') & (df['height']==20) & (df['width']==397) | (df['width']==382)]['text'].reset_index(drop=True)\n",
    "            #print(sold_by)\n",
    "            final_dfs = pd.concat([name, rating, review, price, sold_by],  axis=1)\n",
    "            final_dfs.columns = ['category1_name','category1_rating','category1_review','category1_price','category1_sold_by']\n",
    "            #print(header_df)\n",
    "\n",
    "            indexx = []\n",
    "            field = []\n",
    "            value = []\n",
    "            j=1\n",
    "            for index,content in final_dfs.iterrows():\n",
    "                for i in range(len(content)):\n",
    "                    indexx.append(f\" {from_file}.{l+1}.{j}.{i+1}\")\n",
    "                j=j+1\n",
    "            #print(index)\n",
    "            file_name = file_name.split('.') # for file number\n",
    "            file_name=file_name[0]\n",
    "            index_file_mapping[file_name] = from_file   # for mapping \n",
    "\n",
    "\n",
    "            j=0        \n",
    "            for index,content in final_dfs.iterrows():\n",
    "                for i in range(len(content)):\n",
    "                    field.append(content.index[i])\n",
    "                    value.append(content[i])\n",
    "                    j = j+1\n",
    "\n",
    "            #from_file = from_file + 1\n",
    "            # series\n",
    "            s1 = pd.Series(indexx) \n",
    "            s2 = pd.Series(field)\n",
    "            s3 = pd.Series(value)\n",
    "            final_df =pd.concat([s1, s2, s3], axis=1)\n",
    "            final_df.columns = ['index','field','value']\n",
    "            final_df = final_df.sort_values(by=['field','index'])\n",
    "            #print(final_df)\n",
    "            final_json_to_csv_df = pd.concat([final_json_to_csv_df, final_df])\n",
    "            #print(final_json_to_csv_df)\n",
    "\n",
    "        # for body\n",
    "        else: \n",
    "            sold_by = df[(df['depth']==14) & (df['element']=='DIV') & (df['height']==20) & (df['x']==633)]['text'].reset_index(drop=True)\n",
    "            #print(sold_by)\n",
    "            price = df[(df['depth']==17) & (df['element']=='SPAN') & (df['height']==25) & (df['width']==79.046875)]['text'].reset_index(drop=True)\n",
    "            #print(price)\n",
    "            review = df[(df['depth']==16) & (df['element']=='I') & (df['height']==12)]['attributes.class'].reset_index(drop=True)\n",
    "            #print(review)\n",
    "            rcount = df[(df['depth']==15) & (df['element']=='DIV') & (df['height']==40) & (df['x']==633)]['text'].reset_index(drop=True)\n",
    "            rcount = rcount[~rcount.str.contains(\"FREE\")] # drop row which conain free text\n",
    "            rcount = rcount[~rcount.str.contains(\"19.95\")]# drop row which conain free 19.95\n",
    "            #print(rcount)\n",
    "            rating_count = rcount.astype(str).str.split(' | ratings',expand=True)[0].str.strip(\"()\").reset_index(drop=True)\n",
    "            #print(rating_count)\n",
    "            description = rcount.astype(str).str.split(')',expand=True)[1].reset_index(drop=True)\n",
    "           # print(description)\n",
    "            final_dfs = pd.concat([sold_by, price, review, rating_count, description],  axis=1)\n",
    "            final_dfs.columns = ['category2_name','category2_price','category2_review','category2_rating_count','category2_description']\n",
    "            #print(final_dfs)\n",
    "\n",
    "            indexx = []\n",
    "            field = []\n",
    "            value = []\n",
    "            j=1\n",
    "            for index,content in final_dfs.iterrows():\n",
    "                for i in range(len(content)):\n",
    "                    indexx.append(f\" {from_file}.{l+1}.{j}.{i+1}\")\n",
    "                j=j+1\n",
    "            #print(index)\n",
    "            file_name = file_name.split('.') # for file number\n",
    "            file_name=file_name[0]\n",
    "            index_file_mapping[file_name] = from_file   # for mapping \n",
    "\n",
    "\n",
    "            j=0        \n",
    "            for index,content in final_dfs.iterrows():\n",
    "                for i in range(len(content)):\n",
    "                    field.append(content.index[i])\n",
    "                    value.append(content[i])\n",
    "                    j = j+1\n",
    "\n",
    "            #from_file = from_file + 1\n",
    "            # series\n",
    "            s1 = pd.Series(indexx) \n",
    "            s2 = pd.Series(field)\n",
    "            s3 = pd.Series(value)\n",
    "            final_df =pd.concat([s1, s2, s3], axis=1)\n",
    "            final_df.columns = ['index','field','value']\n",
    "            final_df = final_df.sort_values(by=['field','index'])\n",
    "            #print(final_df)\n",
    "            final_json_to_csv_df = pd.concat([final_json_to_csv_df, final_df])\n",
    "#final_json_to_csv_df.fillna('Nan')\n",
    "print(final_json_to_csv_df)\n",
    "#final_json_to_csv_df.to_csv(\"final_task444.csv\",index=False)\n",
    "index_file_mapping_df = pd.DataFrame(list(index_file_mapping.items()), columns = ['file_name','Indexing'])\n",
    "#print(index_file_mapping_df)\n",
    "#index_file_mapping_df.to_csv('map_index_t4.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "path_to_json = 'E:/growbydata/Growbydata/task_4/amazoncpi/json/'\n",
    "json_files = [pos_json for pos_json in os.listdir(path_to_json) if pos_json.endswith('.json')]\n",
    "final_json_to_csv_df = pd.DataFrame()\n",
    "from_file = 0\n",
    "index_file_mapping={}\n",
    "\n",
    "for file_name in (json_files):\n",
    "    #print(file_name)\n",
    "    data = json.load(open(f\"./amazoncpi/json/{file_name}\"))\n",
    "    df = pd.json_normalize(data[\"data\"])\n",
    "    df['file_from'] = file_name\n",
    "    #print(df)\n",
    "    # for body data\n",
    "    category = ['category1', 'category2']\n",
    "    from_file = from_file + 1\n",
    "    for l in range(len(category)):\n",
    "        if (l == 0):\n",
    "            \n",
    "            # for header\n",
    "            name = df[(df['depth']==16) & (df['element']=='H5')]['text'].reset_index(drop=True)\n",
    "            #print(name)\n",
    "            rating = df[(df['depth']==16)& (df['element']=='SPAN') & (df['height']==16) & (df['x']==716.40625)]['text'].reset_index(drop=True)\n",
    "            #print(rating)\n",
    "            review = df[(df['depth']==17) & (df['element']=='I') & (df['height']==18)]['attributes.class'].reset_index(drop=True)\n",
    "            #print(review)\n",
    "            price = df[(df['depth']==21) & (df['element']=='SPAN') & (df['height']==25) & (df['x']==633)]['text'].unique()\n",
    "            price = pd.Series(price)\n",
    "            #print(price)\n",
    "            #sold_by = df[(df['depth']==17) & (df['element']=='DIV') & (df['height']==20) & (df['width']==397) | (df['width']==382)]['text'].reset_index(drop=True)\n",
    "            #print(sold_by)\n",
    "            #final_dfs = pd.concat([name, rating, review, price, sold_by],  axis=1)\n",
    "            #final_dfs.columns = ['category1_name','category1_rating','category1_review','category1_price','category1_sold_by']\n",
    "            #print(final_dfs['category1_sold_by'])## error\n",
    "            final_dfs = pd.concat([name, rating, review, price],  axis=1)\n",
    "            final_dfs.columns = ['category1_name','category1_rating','category1_review','category1_price']\n",
    "\n",
    "            indexx = []\n",
    "            field = []\n",
    "            value = []\n",
    "            j=1\n",
    "            for index,content in final_dfs.iterrows():\n",
    "                for i in range(len(content)):\n",
    "                    indexx.append(f\" {from_file}.{l+1}.{j}.{i+1}\")\n",
    "                j=j+1\n",
    "            #print(index)\n",
    "            file_name = file_name.split('.') # for file number\n",
    "            file_name=file_name[0]\n",
    "            index_file_mapping[file_name] = from_file   # for mapping \n",
    "\n",
    "\n",
    "            j=0        \n",
    "            for index,content in final_dfs.iterrows():\n",
    "                for i in range(len(content)):\n",
    "                    field.append(content.index[i])\n",
    "                    value.append(content[i])\n",
    "                    j = j+1\n",
    "\n",
    "            #from_file = from_file + 1\n",
    "            # series\n",
    "            s1 = pd.Series(indexx) \n",
    "            s2 = pd.Series(field)\n",
    "            s3 = pd.Series(value)\n",
    "            final_df =pd.concat([s1, s2, s3], axis=1)\n",
    "            final_df.columns = ['index','field','value']\n",
    "            final_df = final_df.sort_values(by=['field','index'])\n",
    "            #print(final_df)\n",
    "            final_json_to_csv_df = pd.concat([final_json_to_csv_df, final_df])\n",
    "            #print(final_json_to_csv_df)\n",
    "\n",
    "        # for body\n",
    "        else: \n",
    "            sold_by = df[(df['depth']==14) & (df['element']=='DIV') & (df['height']==20) & (df['x']==633)]['text'].reset_index(drop=True)\n",
    "            #print(sold_by)\n",
    "            price = df[(df['depth']==17) & (df['element']=='SPAN') & (df['height']==25) & (df['width']==79.046875)]['text'].reset_index(drop=True)\n",
    "            #print(price)\n",
    "            review = df[(df['depth']==16) & (df['element']=='I') & (df['height']==12)]['attributes.class'].reset_index(drop=True)\n",
    "            #print(review)\n",
    "            rcount = df[(df['depth']==15) & (df['element']=='DIV') & (df['height']==40) & (df['x']==633)]['text'].reset_index(drop=True)\n",
    "            rcount = rcount[~rcount.str.contains(\"FREE\")] # drop row which conain free text\n",
    "            rcount = rcount[~rcount.str.contains(\"19.95\")]# drop row which conain free 19.95\n",
    "            #print(rcount)\n",
    "            rating_count = rcount.astype(str).str.split(' | ratings',expand=True)[0].str.strip(\"()\").reset_index(drop=True)\n",
    "            #print(rating_count)\n",
    "            description = rcount.astype(str).str.split(')',expand=True)[1].reset_index(drop=True)\n",
    "           # print(description)\n",
    "            final_dfs = pd.concat([sold_by, price, review, rating_count, description],  axis=1)\n",
    "            final_dfs.columns = ['category2_name','category2_price','category2_review','category2_rating_count','category2_description']\n",
    "            #print(final_dfs)\n",
    "\n",
    "            indexx = []\n",
    "            field = []\n",
    "            value = []\n",
    "            j=1\n",
    "            for index,content in final_dfs.iterrows():\n",
    "                for i in range(len(content)):\n",
    "                    indexx.append(f\" {from_file}.{l+1}.{j}.{i+1}\")\n",
    "                j=j+1\n",
    "            #print(index)\n",
    "            file_name = file_name.split('.') # for file number\n",
    "            file_name=file_name[0]\n",
    "            index_file_mapping[file_name] = from_file   # for mapping \n",
    "\n",
    "\n",
    "            j=0        \n",
    "            for index,content in final_dfs.iterrows():\n",
    "                for i in range(len(content)):\n",
    "                    field.append(content.index[i])\n",
    "                    value.append(content[i])\n",
    "                    j = j+1\n",
    "\n",
    "            #from_file = from_file + 1\n",
    "            # series\n",
    "            s1 = pd.Series(indexx) \n",
    "            s2 = pd.Series(field)\n",
    "            s3 = pd.Series(value)\n",
    "            final_df =pd.concat([s1, s2, s3], axis=1)\n",
    "            final_df.columns = ['index','field','value']\n",
    "            final_df = final_df.sort_values(by=['field','index'])\n",
    "            #print(final_df)\n",
    "            final_json_to_csv_df = pd.concat([final_json_to_csv_df, final_df])\n",
    "final_json_to_csv_df = final_json_to_csv_df.fillna('Nan')\n",
    "#print(final_json_to_csv_df)\n",
    "final_json_to_csv_df.to_csv(\"final_task14.csv\",index=False)\n",
    "#index_file_mapping_df = pd.DataFrame(list(index_file_mapping.items()), columns = ['file_name','Indexing'])\n",
    "#print(index_file_mapping_df)\n",
    "#index_file_mapping_df.to_csv('map_index_t4.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
